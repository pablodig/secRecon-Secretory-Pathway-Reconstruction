{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c99e384",
   "metadata": {},
   "source": [
    "# Sec Recon Network Visualization\n",
    "This notebook is for the visualization of the Secretory Pathway Reconstruction. Here we try different approaches  the visualization. First, we generate a python dictionary with all the necessary information that will be used for downstream analysys. The first analysis is bases on a dimensionality reduction of the data set for UMAP plotting of the genes. In the second analysis we generate a network of the Sec Recon in which all the nodes represent genes interconnected by the processes they share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Circle\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from itertools import combinations\n",
    "from utils import integrate_dicts, get_gene_color, flatten_processes, adjust_color_alpha, categorize_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c45db",
   "metadata": {},
   "source": [
    "## 1 Generate a \"gene_dict\" dictionary with all the necessary information stored into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate secrecon dataframe\n",
    "secrecon = pd.read_csv(\"Input/masterTable.csv\")\n",
    "unprocesses = pd.read_excel(\"Input/uniqueProcesses_finalOntology.xlsx\", sheet_name=\"Final ontology\")\n",
    "complexes = pd.read_csv(\"Input/Complexes.csv\")\n",
    "cho2human_mapping = pd.read_csv(\"Orthologs/cho2human_mapping.tsv\", sep='\\t')\n",
    "subcell = pd.read_csv(\"Input/subcellular_localization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subcell_dict = dict(zip(subcell['Gene_name_canonical'], subcell['consensus graph-based annotation (this study)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126777da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarization of the subcellular compartments to be merged with the compartments in the Sec Recon dataset\n",
    "\n",
    "for key in subcell_dict:\n",
    "    if subcell_dict[key] == 'early_endosome':\n",
    "        subcell_dict[key] = list(['Early Endosome'])\n",
    "    elif subcell_dict[key] == 'centrosome':\n",
    "        subcell_dict[key] = list(['Centrosome'])\n",
    "    elif subcell_dict[key] == 'ER':\n",
    "        subcell_dict[key] = list(['Endoplasmic Reticulum'])\n",
    "    elif subcell_dict[key] == 'mitochondrion':\n",
    "        subcell_dict[key] = list(['Mitochondria'])\n",
    "    elif subcell_dict[key] == 'stress_granule':\n",
    "        subcell_dict[key] = list(['Stress Granule'])\n",
    "    elif subcell_dict[key] == 'unclassified':\n",
    "        subcell_dict[key] = None\n",
    "    elif subcell_dict[key] == 'peroxisome':\n",
    "        subcell_dict[key] = list(['Peroxisome'])\n",
    "    elif subcell_dict[key] == '14-3-3_scaffold':\n",
    "        subcell_dict[key] = None\n",
    "    elif subcell_dict[key] == 'recycling_endosome':\n",
    "        subcell_dict[key] = list(['Recycling Endosome'])\n",
    "    elif subcell_dict[key] == 'plasma_membrane':\n",
    "        subcell_dict[key] = list(['Plasma Membrane'])\n",
    "    elif subcell_dict[key] == 'lysosome':\n",
    "        subcell_dict[key] = list(['Lysosome'])\n",
    "    elif subcell_dict[key] == 'translation':\n",
    "        subcell_dict[key] = list(['Translation'])\n",
    "    elif subcell_dict[key] == 'actin_cytoskeleton':\n",
    "        subcell_dict[key] = list(['Actin Cytoskeleton'])\n",
    "    elif subcell_dict[key] == 'cytosol':\n",
    "        subcell_dict[key] = list(['Cytoplasm'])\n",
    "    elif subcell_dict[key] == 'nucleus':\n",
    "        subcell_dict[key] = list(['Nucleus'])\n",
    "    elif subcell_dict[key] == 'ERGIC':\n",
    "        subcell_dict[key] = list(['ERGIC'])\n",
    "    elif subcell_dict[key] == 'p-body':\n",
    "        subcell_dict[key] = list(['P-Body'])\n",
    "    elif subcell_dict[key] == 'trans-Golgi':\n",
    "        subcell_dict[key] = list(['trans-Golgi'])\n",
    "    elif subcell_dict[key] == 'nucleolus':\n",
    "        subcell_dict[key] = list(['Nucleolus'])\n",
    "    elif subcell_dict[key] == 'proteasome':\n",
    "        subcell_dict[key] = list(['Proteasome'])\n",
    "    elif subcell_dict[key] == 'Golgi':\n",
    "        subcell_dict[key] = list(['Golgi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9babbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map CHO IDs to Human IDs to fill in blank spaces\n",
    "counter = 0\n",
    "cho_id_lookup = dict(zip(cho2human_mapping['HUMAN_ID'], cho2human_mapping['CHO_ID']))\n",
    "\n",
    "for index, row in secrecon.iterrows():\n",
    "    if pd.isna(row['CHO_ENTREZID']) or row['CHO_ENTREZID'] == '':\n",
    "        human_id = row['ENTREZID']\n",
    "        cho_id = cho_id_lookup.get(human_id)\n",
    "        counter += 1\n",
    "        if cho_id is not None:\n",
    "            secrecon.at[index, 'CHO_ENTREZID'] = cho_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a008de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the information if the Subcellular localization column in order to keep just the compartment name\n",
    "secrecon['Subcellular location [CC]'] = secrecon['Subcellular location [CC]'].apply(categorize_location)\n",
    "secrecon['Subcellular_location_2'] = secrecon['SYMBOL'].map(subcell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84daef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate dictionaries\n",
    "\n",
    "# Process Dict\n",
    "process_dict = {}\n",
    "\n",
    "for index, row in unprocesses.iterrows():\n",
    "    system = row['System']\n",
    "    subsystem = row['Subsystem'] if pd.notna(row['Subsystem']) else None\n",
    "    process = row['Process'] if pd.notna(row['Process']) else None\n",
    "    subprocess = row['Subprocess'] if pd.notna(row['Subprocess']) else None\n",
    "    \n",
    "    if system not in process_dict:\n",
    "        process_dict[system] = []\n",
    "        \n",
    "    process_dict[system].append({k: v for k, v in {\n",
    "        'Subsystem': subsystem,\n",
    "        'Process': process,\n",
    "        'Subprocess': subprocess\n",
    "    }.items() if v is not None})\n",
    "\n",
    "gene_dict = {}\n",
    "for index, row in secrecon.iterrows():\n",
    "    gene = row['SYMBOL']\n",
    "    # Grab the processes and filter out any NaN values\n",
    "    # Add the subcellular localizations\n",
    "    processes = row[['Process.1', 'Process.2', 'Process.3', 'Process.4', 'Process.5',\n",
    "                     'Process.6', 'Process.7', 'Process.8', 'Process.9', 'Process.10']].dropna().tolist()\n",
    "    if pd.isna(row['Subcellular_location_2']):\n",
    "        localization = row['Subcellular location [CC]']\n",
    "    else:\n",
    "        localization = row['Subcellular_location_2']\n",
    "    \n",
    "    gene_dict[gene] = {'processes': processes, 'subcellular_localization': localization}\n",
    "    \n",
    "\n",
    "#Complexes dict\n",
    "\n",
    "# Pre-select all the complexes in Human\n",
    "complexes = complexes[complexes['Organism'] == 'Human']\n",
    "gene_complex_dict = {}\n",
    "\n",
    "for index, row in complexes.iterrows():\n",
    "    gene_symbol = row['SYMBOL']\n",
    "    complex_name = row['ComplexName']\n",
    "    # Check if the gene symbol is already a key in the dictionary\n",
    "    if gene_symbol in gene_complex_dict:\n",
    "        # Append the complex name to the existing list\n",
    "        gene_complex_dict[gene_symbol].append(complex_name)\n",
    "    else:\n",
    "        # Create a new key with the complex name as the first item in the list\n",
    "        gene_complex_dict[gene_symbol] = [complex_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate gene_dict with info from the \"process_dict\"\n",
    "gene_dict = integrate_dicts(gene_dict, process_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the complexes to the gene_dict. If a gene is not part of any complex, we will put 'Not part of any complex'\n",
    "for gene in gene_dict:\n",
    "    gene_dict[gene]['complex'] = gene_complex_dict.get(gene)#, 'Not part of any complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589fcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes with no subcellular localization\n",
    "count = 0\n",
    "for key in gene_dict:\n",
    "    if gene_dict[key]['subcellular_localization'] == []:\n",
    "        print(key,gene_dict[key]['subcellular_localization'])\n",
    "        count += 1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d3841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gene_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(gene_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d72263",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('process_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(process_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bef11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d8d0f",
   "metadata": {},
   "source": [
    "## 2 Dimensionality reduction / one hot encoding for UMAP visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import umap\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "# Flatten the dictionary\n",
    "flattened_data = []\n",
    "for gene, attributes in gene_dict.items():\n",
    "    for key, values in attributes.items():\n",
    "        if key == 'subcellular_localization':  # Skip this subkey\n",
    "            continue\n",
    "        if values is None:\n",
    "            continue\n",
    "        if not isinstance(values, list):\n",
    "            values = [values]\n",
    "        for value in values:\n",
    "            # Tag each attribute\n",
    "            attribute_tag = f\"{key}_{value}\"\n",
    "            flattened_data.append({'gene': gene, 'attribute_tag': attribute_tag, 'attribute_value': value, 'attribute_type': key})\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "one_hot_encoded_df = pd.get_dummies(df, columns=['attribute_value'], prefix='', prefix_sep='')\n",
    "\n",
    "# Assign higher values to 'complex' attributes\n",
    "complex_multiplier = 2  # Define your multiplier for 'complex' attributes\n",
    "for index, row in df.iterrows():\n",
    "    if row['attribute_type'] == 'complex':\n",
    "        for column in one_hot_encoded_df.columns:\n",
    "            if column in row['attribute_tag']:\n",
    "                one_hot_encoded_df.at[index, column] *= complex_multiplier\n",
    "\n",
    "# Group by 'gene'\n",
    "final_encoded_df = one_hot_encoded_df.groupby('gene').sum().reset_index()\n",
    "\n",
    "\n",
    "final_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde67008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data (excluding the gene column for the KNN input)\n",
    "X = final_encoded_df.drop('gene', axis=1)\n",
    "\n",
    "# Consistent distance metric\n",
    "distance_metric = 'euclidean'  # Choose 'euclidean', 'cosine', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN model with consistent n_neighbors\n",
    "n_neighbors = 20  # Adjust as needed\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors, metric=distance_metric)\n",
    "knn.fit(X)\n",
    "distances, indices = knn.kneighbors(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f8b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply UMAP with consistent parameters\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    min_dist=0.01,  # Adjust as needed\n",
    "    n_components=2,\n",
    "    spread=40,  # Adjust as needed\n",
    "    random_state=42,\n",
    "    metric=distance_metric\n",
    ")\n",
    "embedding = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc403249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Graph for Leiden Algorithm\n",
    "G = nx.Graph()\n",
    "for idx, neighbors in enumerate(indices):\n",
    "    for neighbor in neighbors:\n",
    "        G.add_edge(idx, neighbor)\n",
    "\n",
    "# Convert to iGraph\n",
    "ig_graph = ig.Graph.from_networkx(G)\n",
    "\n",
    "# Apply Leiden Algorithm with adjustable resolution\n",
    "resolution_parameter = 1.4\n",
    "partition = la.find_partition(ig_graph, la.RBConfigurationVertexPartition, \n",
    "                              resolution_parameter=resolution_parameter)\n",
    "\n",
    "# Visualize UMAP with Leiden Clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "cluster_membership = np.array(partition.membership)\n",
    "\n",
    "# Find unique clusters\n",
    "unique_clusters = np.unique(cluster_membership)\n",
    "\n",
    "# Create a color map\n",
    "colors = plt.cm.get_cmap('viridis', len(unique_clusters))\n",
    "\n",
    "# Plot each cluster with its specific color\n",
    "for cluster_id in unique_clusters:\n",
    "    plt.scatter(\n",
    "        embedding[cluster_membership == cluster_id, 0],\n",
    "        embedding[cluster_membership == cluster_id, 1],\n",
    "        color=colors(cluster_id),\n",
    "        label=f'Cluster {cluster_id}',\n",
    "        s=40,  # Adjust point size\n",
    "        alpha=0.8  # Adjust transparency\n",
    "    )\n",
    "\n",
    "plt.title('UMAP Projection with Leiden Clustering')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.legend(title='Cluster ID')  # Add a legend\n",
    "plt.savefig('umap_leiden_clusters.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_colors = {\n",
    "    'Actin Cytoskeleton': (0.7, 0.4, 0.2, 1.0),\n",
    "    'Centrosome': (0.0, 0.5, 0.5, 1.0),\n",
    "    'ERGIC': (1.0, 0.6, 0.0, 1.0),\n",
    "    'Endosome': (0.0, 0.7, 0.3, 1.0), \n",
    "    'Recycling Endosome': (0.3, 0.0, 0.7, 1.0), \n",
    "    'Early Endosome': (0.7, 0.0, 0.4, 1.0), \n",
    "    'Plasma Membrane': (0.5, 0.5, 0.0, 1.0), \n",
    "    'Golgi': (0.1, 0.9, 0.1, 1.0), \n",
    "    'cis-Golgi': (0.2, 0.8, 0.6, 1.0),\n",
    "    'trans-Golgi': (0.4, 0.8, 0.4, 1.0), \n",
    "    'Nucleus': (0.9, 0.1, 0.1, 1.0),\n",
    "    'Nucleolus': (0.5, 0.1, 0.1, 1.0),\n",
    "    'Phagosome': (0.6, 0.3, 0.0, 1.0),\n",
    "    'Proteasome': (0.3, 0.3, 0.9, 1.0),\n",
    "    'Mitochondria': (0.9, 0.5, 0.5, 1.0),\n",
    "    'Lysosome': (0.5, 0.9, 0.8, 1.0),  \n",
    "    'Cytoplasm': (0.4, 0.7, 0.9, 1.0),\n",
    "    'Endoplasmic Reticulum': (0.7, 0.7, 0.3, 1.0),\n",
    "    'Stress Granule': (0.8, 0.4, 0.0, 1.0),\n",
    "    'Translation': (0.8, 0.2, 0.8, 1.0)\n",
    "}\n",
    "\n",
    "# Extract subcellular localization for each gene\n",
    "subcellular_localization_df = pd.DataFrame(\n",
    "    [(gene, locs[0]) for gene, attrs in gene_dict.items() for locs in [attrs.get('subcellular_localization', [''])] if locs],\n",
    "    columns=['gene', 'subcellular_localization'])\n",
    "\n",
    "\n",
    "# Convert UMAP embedding to a DataFrame\n",
    "embedding_df = pd.DataFrame(embedding, columns=['UMAP_1', 'UMAP_2'])\n",
    "\n",
    "# Add a 'gene' column from your original DataFrame for alignment\n",
    "embedding_df['gene'] = final_encoded_df['gene'].values\n",
    "\n",
    "# Merge the UMAP results with subcellular localization\n",
    "umap_localization_df = pd.merge(embedding_df, subcellular_localization_df, on='gene')\n",
    "\n",
    "# Now plot with color coding\n",
    "plt.figure(figsize=(40, 40))\n",
    "for loc, color in localization_colors.items():\n",
    "    # Find the subset of the data frame that corresponds to the current localization\n",
    "    subset = umap_localization_df[umap_localization_df['subcellular_localization'] == loc]\n",
    "    # Plot this subset with the predefined color\n",
    "    plt.scatter(subset['UMAP_1'], subset['UMAP_2'], label=loc, color=color, s=550, alpha=0.5)\n",
    "\n",
    "plt.legend(prop={'size': 25}, loc='lower left', bbox_to_anchor=(0.77, 0.65))\n",
    "plt.subplots_adjust(right=0.75)\n",
    "\n",
    "plt.title('2D UMAP Projection Colored by Subcellular Localization')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f1dd2",
   "metadata": {},
   "source": [
    "## 3. Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, ceil\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_colors = {\n",
    "    'Actin Cytoskeleton': (0.7, 0.4, 0.2, 1.0),\n",
    "    'Centrosome': (0.0, 0.5, 0.5, 1.0),\n",
    "    'ERGIC': (1.0, 0.6, 0.0, 1.0),\n",
    "    'Endosome': (0.0, 0.7, 0.3, 1.0), \n",
    "    'Recycling Endosome': (0.3, 0.0, 0.7, 1.0), \n",
    "    'Early Endosome': (0.7, 0.0, 0.4, 1.0), \n",
    "    'Plasma Membrane': (0.5, 0.5, 0.0, 1.0), \n",
    "    'Golgi': (0.1, 0.9, 0.1, 1.0), \n",
    "    'cis-Golgi': (0.2, 0.8, 0.6, 1.0),\n",
    "    'trans-Golgi': (0.4, 0.8, 0.4, 1.0), \n",
    "    'Nucleus': (0.9, 0.1, 0.1, 1.0),\n",
    "    'Nucleolus': (0.5, 0.1, 0.1, 1.0),\n",
    "    'Phagosome': (0.6, 0.3, 0.0, 1.0),\n",
    "    'Proteasome': (0.3, 0.3, 0.9, 1.0),\n",
    "    'Mitochondria': (0.9, 0.5, 0.5, 1.0),\n",
    "    'Lysosome': (0.5, 0.9, 0.8, 1.0),  \n",
    "    'Cytoplasm': (0.4, 0.7, 0.9, 1.0),\n",
    "    'Endoplasmic Reticulum': (0.7, 0.7, 0.3, 1.0),\n",
    "    'Stress Granule': (0.8, 0.4, 0.0, 1.0),\n",
    "    'Translation': (0.8, 0.2, 0.8, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f3bba",
   "metadata": {},
   "source": [
    "### 3.1 Generate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e881b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the network\n",
    "G = nx.Graph()\n",
    "\n",
    "# Adding nodes\n",
    "for gene in gene_dict:\n",
    "    G.add_node(gene)\n",
    "\n",
    "# Constants for edge weights\n",
    "PROCESSES_WEIGHT = 1\n",
    "PROCESS_WEIGHT = 0.5\n",
    "SUBSYSTEM_WEIGHT = 0.25\n",
    "SYSTEM_WEIGHT = 0.125\n",
    "COMPLEX_WEIGHT = 2\n",
    "\n",
    "# Add edges to the nodes\n",
    "for gene1, gene2 in combinations(gene_dict.keys(), 2):  # 2 for pairs\n",
    "    # Calculate shared processes\n",
    "    shared_processes = len(set(gene_dict[gene1]['processes']).intersection(gene_dict[gene2]['processes']))\n",
    "    # Calculate shared process: this may seem redundant but genes with subprocesses have proceeses as a parent category\n",
    "    if gene_dict[gene1]['process'] is None or gene_dict[gene2]['process'] is None:\n",
    "        shared_process = 0\n",
    "    else:\n",
    "        shared_process = len(set(gene_dict[gene1]['process']).intersection(gene_dict[gene2]['process']))\n",
    "    # Calculate shared subsystem\n",
    "    if gene_dict[gene1]['subsystem'] is None or gene_dict[gene2]['subsystem'] is None:\n",
    "        shared_subsystem = 0\n",
    "    else:\n",
    "        shared_subsystem = len(set(gene_dict[gene1]['subsystem']).intersection(gene_dict[gene2]['subsystem']))\n",
    "    # Calculate shared system\n",
    "    if gene_dict[gene1]['system'] is None or gene_dict[gene2]['system'] is None:\n",
    "        shared_system = 0\n",
    "    else:\n",
    "        shared_system = len(set(gene_dict[gene1]['system']).intersection(gene_dict[gene2]['system']))\n",
    "    # Check for shared complex\n",
    "    if gene_dict[gene1]['complex'] is None or gene_dict[gene2]['complex'] is None:\n",
    "        shared_complex = 0\n",
    "    else:\n",
    "        shared_complex = len(set(gene_dict[gene1]['complex'] or []).intersection(gene_dict[gene2]['complex'] or []))\n",
    "        \n",
    "    shared_processes = shared_processes*PROCESSES_WEIGHT\n",
    "    shared_process = shared_process*PROCESS_WEIGHT\n",
    "    shared_subsystem = shared_subsystem*SUBSYSTEM_WEIGHT\n",
    "    shared_system = shared_system*SYSTEM_WEIGHT\n",
    "    shared_complex = shared_complex*COMPLEX_WEIGHT\n",
    "    edge_weight = shared_processes + shared_process + shared_subsystem + shared_system + shared_complex\n",
    "    G.add_edge(gene1, gene2, weight=edge_weight)\n",
    "    \n",
    "\n",
    "# Draw the graph layout\n",
    "pos = nx.spring_layout(G, seed=42, iterations=60, k=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f5984",
   "metadata": {},
   "source": [
    "### 3.2 Reorganize nodes at the edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to track the highest weight for each node\n",
    "highest_weight = {}\n",
    "\n",
    "# Iterate over all edges to update the highest weight for each node\n",
    "for u, v, data in G.edges(data=True):\n",
    "    weight = data['weight']\n",
    "    # Update the highest weight for nodes u and v\n",
    "    if u not in highest_weight or highest_weight[u] < weight:\n",
    "        highest_weight[u] = weight\n",
    "    if v not in highest_weight or highest_weight[v] < weight:\n",
    "        highest_weight[v] = weight\n",
    "\n",
    "# Initialize the set of low_weight_nodes\n",
    "low_weight_nodes = set()\n",
    "# Add nodes to the set if their highest weight is below 1\n",
    "for node, weight in highest_weight.items():\n",
    "    if weight < 1:\n",
    "        low_weight_nodes.add(node)\n",
    "        \n",
    "# Calculate layout bounds to help define the rectangle area\n",
    "x_values, y_values = zip(*pos.values())\n",
    "plot_width = max(x_values) - min(x_values)\n",
    "plot_height = max(y_values) - min(y_values)\n",
    "\n",
    "# Define the rectangle's bottom right corner and dimensions\n",
    "rect_width = plot_width * 0.15  # 15% of the plot width\n",
    "rect_height = plot_height * 0.15  # 15% of the plot height\n",
    "rect_bottom_right_x = max(x_values)\n",
    "rect_bottom_right_y = min(y_values)\n",
    "\n",
    "# Calculate layout bounds to help define the rectangle area\n",
    "x_values, y_values = zip(*pos.values())\n",
    "min_x_val, max_x_val = min(x_values), max(x_values)  \n",
    "min_y_val, max_y_val = min(y_values), max(y_values)\n",
    "\n",
    "# Calculate the number of low-weight edge nodes for grid dimension calculation\n",
    "num_low_weight_nodes = len(low_weight_nodes)\n",
    "cols = int(round(sqrt(num_low_weight_nodes)))\n",
    "rows = int(ceil(num_low_weight_nodes / cols))\n",
    "\n",
    "# Calculate positions within the rectangle for each low-weight edge node\n",
    "for i, node in enumerate(low_weight_nodes):\n",
    "    col = i % cols\n",
    "    row = i // cols\n",
    "    \n",
    "    # Calculate grid cell position\n",
    "    new_x = rect_bottom_right_x - rect_width + (col + 1) * (rect_width / (cols + 1))\n",
    "    new_y = rect_bottom_right_y + (row + 1) * (rect_height / (rows + 1))\n",
    "    \n",
    "    # Update position\n",
    "    pos[node] = (new_x, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c979e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the network as a GraphML\n",
    "nx.write_graphml(G, 'Network/sec_recon_network.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5bff8",
   "metadata": {},
   "source": [
    "### 3.3 Create the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dce75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "\n",
    "# Only plot edges that are greater than 1 in weight\n",
    "edgelist = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] >= 1]\n",
    "\n",
    "# Draw edges\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edgelist, edge_color='lightgrey')#, \n",
    "                       #width=[G[u][v]['weight'] for u, v in G.edges() if 40 > G[u][v]['weight'] > 2])\n",
    "\n",
    "\n",
    "def adjust_alpha(color, alpha):\n",
    "    return (color[0], color[1], color[2], alpha)\n",
    "\n",
    "# Draw nodes as pie charts\n",
    "for node, (x, y) in pos.items():\n",
    "    localizations = gene_dict[node]['subcellular_localization']\n",
    "    \n",
    "    # Check if the node is part of any complex\n",
    "    is_in_complex = gene_dict[node]['complex'] != 'Not part of any complex'\n",
    "    \n",
    "    # Set alpha value based on whether the node is in a complex\n",
    "    alpha_value = 1.0 if is_in_complex else 0.5\n",
    "    \n",
    "    # Adjust the alpha value of each color\n",
    "    colors = [adjust_alpha(localization_colors[loc], alpha_value) for loc in localizations]\n",
    "    \n",
    "    # Draw pie chart at node position with edgecolor and linewidth\n",
    "    ax.pie([1]*len(localizations), colors=colors, radius=0.012, center=(x, y), wedgeprops=dict(edgecolor='black', linewidth=0.5))\n",
    "    \n",
    "# Get the current axis limits\n",
    "x_values, y_values = zip(*pos.values())\n",
    "min_x, max_x = min(x_values), max(x_values)\n",
    "min_y, max_y = min(y_values), max(y_values)\n",
    "\n",
    "# Set new axis limits\n",
    "ax.set_xlim(min_x - 0.1, max_x + 0.1)\n",
    "ax.set_ylim(min_y - 0.1, max_y + 0.1)\n",
    "\n",
    "# Legend\n",
    "legend_patches = [mpatches.Patch(color=color, label=category) for category, color in localization_colors.items()]\n",
    "plt.legend(handles=legend_patches, prop={'size': 25}, loc='lower left', bbox_to_anchor=(0.9, 0.5))\n",
    "plt.subplots_adjust(right=0.75)\n",
    "\n",
    "plt.savefig('Network/secrecon_network_visualization.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881db6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
