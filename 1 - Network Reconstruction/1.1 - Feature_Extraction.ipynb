{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secretory Pathway Features Retrieval\n",
    "This notebook contains all the steps required to generate the Sec Recon dataset from Human Gene Symbols. It retrieves identifiers for Human, Mouse, and CHO, followed by subcellular localization and protein complex information. All gathered data is then compiled into the **\"Secretory Pathway Recon\" Google Sheet**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and define datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../Utils'))\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import Entrez\n",
    "import Request_Utilis\n",
    "from google_sheet import GoogleSheet\n",
    "\n",
    "Entrez.email = \"a.antonakoudis@sartorius.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ----- Generate datasets from Google Sheet ----- #####\n",
    "\n",
    "#Credential file\n",
    "KEY_FILE_PATH = 'credentials.json'\n",
    "\n",
    "#CHO Network Reconstruction + Recon3D_v3 Google Sheet ID\n",
    "SPREADSHEET_ID = '1DaAdZlvMYDqb7g31I5dw-ZCZH52Xj_W3FnQMFUzqmiQ'\n",
    "\n",
    "# Initialize the GoogleSheet object\n",
    "gsheet_file = GoogleSheet(SPREADSHEET_ID, KEY_FILE_PATH)\n",
    "\n",
    "# Read data from the Google Sheet\n",
    "sec_recon_sheet = 'SecRecon'\n",
    "complex_info_sheet = 'Complex Information'\n",
    "\n",
    "sec_recon = gsheet_file.read_google_sheet(sec_recon_sheet)\n",
    "complex_info = gsheet_file.read_google_sheet(complex_info_sheet)\n",
    "\n",
    "# Create a copy of the datasets\n",
    "sec_recon_dc = sec_recon.copy()\n",
    "complex_info_dc = complex_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map Human IDs to CHO IDs from the \"cho2human_mapping\" dataset\n",
    "\n",
    "cho2human_mapping = pd.read_csv(\"Orthologs/cho2human_mapping.tsv\", sep='\\t')\n",
    "cho2human_mapping2 = pd.read_excel(\"Orthologs/orthologs.xlsx\", index_col=0)\n",
    "cho2human_mapping2['Human GeneID'] = pd.to_numeric(cho2human_mapping2['Human GeneID'], errors='coerce')\n",
    "cho2human_mapping2['Human GeneID'] = cho2human_mapping2['Human GeneID'].astype('Int64')\n",
    "\n",
    "cho_id_lookup = dict(zip(cho2human_mapping['HUMAN_ID'], cho2human_mapping['CHO_ID'])) #convert to dict for mapping\n",
    "cho_id_lookup2 = dict(zip(cho2human_mapping2['Human GeneID'], cho2human_mapping2['CHO GeneID'])) #convert to dict for mapping\n",
    "\n",
    "for index, row in sec_recon_dc.iterrows():\n",
    "    if pd.isna(row['CHO ENTREZID']) or row['CHO ENTREZID'] == '':\n",
    "        try:\n",
    "            human_id = int(row['HUMAN ENTREZID'])\n",
    "            cho_id = cho_id_lookup.get(human_id)\n",
    "            if cho_id is not None:\n",
    "                sec_recon_dc.at[index, 'CHO ENTREZID'] = cho_id\n",
    "            else:\n",
    "                try:\n",
    "                    cho_id = cho_id_lookup2.get(human_id)\n",
    "                    if cho_id is not None:\n",
    "                        sec_recon_dc.at[index, 'CHO ENTREZID'] = cho_id\n",
    "                except ValueError:\n",
    "                    print(f'{human_id} is not a valid Human Entrez ID')      \n",
    "        except ValueError:\n",
    "            print(f'{human_id} is not a valid Human Entrez ID')\n",
    "            continue        \n",
    "\n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated on CHO Entrez IDs from cho2human dataset\")\n",
    "else:\n",
    "    print('CHO Entrez IDs from \"cho2human_mapping\" dataset are up-to-date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve Human CHO and Mouse Entrez IDs\n",
    "Here we use the fucntion get_entrez_id from the **Request Utilis** module to fetch the Entrez IDs for Human and then use this as input to retrieve information for CHO and Mouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Human Entrez ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update Human Entrez IDs\n",
    "for i,row in sec_recon_dc.iterrows():\n",
    "    if pd.isnull(row['HUMAN ENTREZID']) or row['HUMAN ENTREZID'] == '':\n",
    "        human_entrez = Request_Utilis.get_entrez_id(row['GENE SYMBOL'])\n",
    "        sec_recon_dc.at[i, 'HUMAN ENTREZID'] = human_entrez\n",
    "\n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "else:\n",
    "    print('Human Entrez IDs are up-to-date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 CHO Entrez IDs from other databases\n",
    "Before running the **get_gene_id** function on CHO genes, we first populate some of the CHO genes with a mapping of orthologs based on our own dataset comprised from different databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Human IDs to CHO IDs from the \"cho2human_mapping\" dataset\n",
    "\n",
    "cho2human_mapping = pd.read_csv(\"Orthologs/cho2human_mapping.tsv\", sep='\\t')\n",
    "cho2human_mapping2 = pd.read_excel(\"Orthologs/orthologs.xlsx\", index_col=0)\n",
    "cho2human_mapping2['Human GeneID'] = pd.to_numeric(cho2human_mapping2['Human GeneID'], errors='coerce')\n",
    "cho2human_mapping2['Human GeneID'] = cho2human_mapping2['Human GeneID'].astype('Int64')\n",
    "\n",
    "cho_id_lookup = dict(zip(cho2human_mapping['HUMAN_ID'], cho2human_mapping['CHO_ID'])) #convert to dict for mapping\n",
    "cho_id_lookup2 = dict(zip(cho2human_mapping2['Human GeneID'], cho2human_mapping2['CHO GeneID'])) #convert to dict for mapping\n",
    "\n",
    "for index, row in sec_recon_dc.iterrows():\n",
    "    if pd.isna(row['CHO ENTREZID']) or row['CHO ENTREZID'] == '':\n",
    "        try:\n",
    "            human_id = int(row['HUMAN ENTREZID'])\n",
    "            cho_id = cho_id_lookup.get(human_id)\n",
    "            if cho_id is not None:\n",
    "                sec_recon_dc.at[index, 'CHO ENTREZID'] = cho_id\n",
    "            else:\n",
    "                try:\n",
    "                    cho_id = cho_id_lookup2.get(human_id)\n",
    "                    if cho_id is not None:\n",
    "                        sec_recon_dc.at[index, 'CHO ENTREZID'] = cho_id\n",
    "                except ValueError:\n",
    "                    print(f'{human_id} is not a valid Human Entrez ID')      \n",
    "        except ValueError:\n",
    "            print(f'{human_id} is not a valid Human Entrez ID')\n",
    "            continue        \n",
    "\n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated on CHO Entrez IDs from cho2human dataset\")\n",
    "else:\n",
    "    print('CHO Entrez IDs from \"cho2human_mapping\" dataset are up-to-date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 CHO and Mouse Entrez IDs \n",
    "Finally we run the **get_gene_ids** function to retrieve CHO and Mouse Entrez IDs by mapping the orthologs using the Human Entrez IDs as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- CHO Entrez IDs -- ##\n",
    "\n",
    "for index, row in sec_recon_dc.iterrows():\n",
    "    if pd.isna(row['CHO ENTREZID']) or row['CHO ENTREZID'] == '':\n",
    "        human_id = row['HUMAN ENTREZID']\n",
    "        cho_ortholog_EntrezID = Request_Utilis.get_gene_ids(human_id, '10029')\n",
    "        if cho_ortholog_EntrezID is not None:\n",
    "            sec_recon_dc.at[index, 'CHO ENTREZID'] = cho_ortholog_EntrezID\n",
    "            \n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated on CHO Entrez IDs from NIH database\")\n",
    "else:\n",
    "    print('CHO Entrez IDs from NIH database are up-to-date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Mouse Entrez IDs -- ##\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "for index, row in sec_recon_dc.iterrows():\n",
    "    if pd.isna(row['MOUSE ENTREZID']) or row['MOUSE ENTREZID'] == '':\n",
    "        human_id = row['HUMAN ENTREZID']\n",
    "        mouse_ortholog_EntrezID = Request_Utilis.get_gene_ids(human_id, '10090')\n",
    "        if mouse_ortholog_EntrezID is not None:\n",
    "            sec_recon_dc.at[index, 'MOUSE ENTREZID'] = mouse_ortholog_EntrezID\n",
    "            loop_counter += 1\n",
    "\n",
    "        if loop_counter >= update_threshold:\n",
    "            if not sec_recon_dc.equals(sec_recon):\n",
    "                gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                print(f\"Google Sheet updated on Mouse Entrez IDs from NIH database after {loop_counter} updates\")\n",
    "            else:\n",
    "                print('Mouse Entrez IDs from NIH database are up-to-date')\n",
    "            loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on Mouse Entrez IDs from NIH database after {loop_counter} updates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensembl IDs\n",
    "In this section we retrieve Ensembl IDs fron NIH database using the **Gene_Info_from_EntrezID** function from the Request Utilis module. Secondarily, we retrieve extra information from other identifiers to fill missing data in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Human Ensembl IDs and Extra Identifiers\n",
    "Here we retrieve the Human Ensembl IDs and Gene Alises and Gene Names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect missing information from NIH database\n",
    "\n",
    "updates = []\n",
    "for i, gene in sec_recon_dc.iterrows():\n",
    "    human_entrezID = gene['HUMAN ENTREZID']\n",
    "    gene_symbol = gene['GENE SYMBOL']\n",
    "    if gene['ALIAS'] == '' or gene['GENENAME'] == '' or gene['HUMAN ENSEMBL'] == '':\n",
    "        print(gene_symbol)\n",
    "        try:\n",
    "            org, gene_symbol, gene_name, gene_synonyms, gene_ensemble, gene_products = Request_Utilis.Gene_Info_from_EntrezID(human_entrezID)\n",
    "            updates.append((i, gene_synonyms, gene_name, gene_ensemble))\n",
    "        except ValueError:\n",
    "            print(f'No valid Entrez ID for gene {gene_symbol}')\n",
    "\n",
    "# Apply the updates outside the loop\n",
    "for i, gene_synonyms, gene_name, gene_ensemble in updates:\n",
    "    sec_recon_dc.at[i, 'ALIAS'] = gene_synonyms\n",
    "    sec_recon_dc.at[i, 'GENENAME'] = gene_name\n",
    "    sec_recon_dc.at[i, 'HUMAN ENSEMBL'] = gene_ensemble\n",
    "    \n",
    "sec_recon_dc['ALIAS'] = sec_recon_dc['ALIAS'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "sec_recon_dc['GENENAME'] = sec_recon_dc['GENENAME'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "sec_recon_dc['HUMAN ENSEMBL'] = sec_recon_dc['HUMAN ENSEMBL'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    " \n",
    "    \n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated.\")\n",
    "else:\n",
    "    print('Human identifiers are up-to-date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 CHO and Mouse Ensembl IDs and Gene Symbols\n",
    "Using the same functionw we retrieve Ensembl IDs and Gene Symbols for CHO and Mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- CHO Ensembl IDs and Gene Symbol -- ##\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "# Collect missing information for CHO identifiers\n",
    "for i, gene in sec_recon_dc.iterrows():\n",
    "    cho_entrezID = str(gene['CHO ENTREZID'])\n",
    "    if cho_entrezID != '':\n",
    "        if (pd.isna(gene['CHO ENSEMBL']) or gene['CHO ENSEMBL'] == '') or (pd.isna(gene['CHO GENE SYMBOL']) or gene['CHO GENE SYMBOL'] == ''):\n",
    "            try:\n",
    "                org, gene_symbol, gene_name, gene_synonyms, gene_ensemble, gene_products = Request_Utilis.Gene_Info_from_EntrezID(cho_entrezID)\n",
    "                if (pd.isna(gene['CHO GENE SYMBOL']) or gene['CHO GENE SYMBOL'] == ''):\n",
    "                    sec_recon_dc.at[i, 'CHO GENE SYMBOL'] = gene_symbol\n",
    "                if (pd.isna(gene['CHO ENSEMBL']) or gene['CHO ENSEMBL'] == ''):\n",
    "                    sec_recon_dc.at[i, 'CHO ENSEMBL'] = gene_ensemble\n",
    "            except ValueError:\n",
    "                print(f'No valid Entrez ID for gene {gene_symbol}')\n",
    "            loop_counter += 1\n",
    "\n",
    "            if loop_counter >= update_threshold:\n",
    "                if not sec_recon_dc.equals(sec_recon):\n",
    "                    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                    print(f\"Google Sheet updated on CHO Ensembl IDs after {loop_counter} updates\")\n",
    "                else:\n",
    "                    print('CHO Ensembl IDs are up-to-date')\n",
    "                loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on CHO Ensembl IDs after {loop_counter} updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Mouse Ensembl IDs and Gene Symbol-- ##\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "# Collect missing information for CHO identifiers\n",
    "for i, gene in sec_recon_dc.iterrows():\n",
    "    mouse_entrezID = str(gene['MOUSE ENTREZID'])\n",
    "    if mouse_entrezID != '':\n",
    "        if (pd.isna(gene['MOUSE ENSEMBL']) or gene['MOUSE ENSEMBL'] == '') or (pd.isna(gene['MOUSE GENE SYMBOL']) or gene['MOUSE GENE SYMBOL'] == ''):\n",
    "            try:\n",
    "                org, gene_symbol, gene_name, gene_synonyms, gene_ensemble, gene_products = Request_Utilis.Gene_Info_from_EntrezID(mouse_entrezID)\n",
    "                if (pd.isna(gene['MOUSE GENE SYMBOL']) or gene['MOUSE GENE SYMBOL'] == ''):\n",
    "                    sec_recon_dc.at[i, 'MOUSE GENE SYMBOL'] = gene_symbol\n",
    "                if (pd.isna(gene['MOUSE ENSEMBL']) or gene['MOUSE ENSEMBL'] == ''):\n",
    "                    sec_recon_dc.at[i, 'MOUSE ENSEMBL'] = gene_ensemble\n",
    "            except ValueError:\n",
    "                print(f'No valid Entrez ID for gene {gene_symbol}')\n",
    "            loop_counter += 1\n",
    "\n",
    "            if loop_counter >= update_threshold:\n",
    "                if not sec_recon_dc.equals(sec_recon):\n",
    "                    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                    print(f\"Google Sheet updated on Mouse Ensembl IDs after {loop_counter} updates\")\n",
    "                else:\n",
    "                    print('Mouse Ensembl IDs are up-to-date')\n",
    "                loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on Mouse Ensembl IDs after {loop_counter} updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Uniprot IDs\n",
    "In this section we retrieve all the Uniprot IDs linked to each gene Entrez ID from NIH database, using the **Gene_Info_from_EntrezID** function from the Request Utilis module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Human Uniprot IDs -- ##\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "# Collect missing information for CHO identifiers\n",
    "for i, gene in sec_recon_dc.iterrows():\n",
    "    human_entrezID = str(gene['HUMAN ENTREZID'])\n",
    "    if human_entrezID != '':\n",
    "        if (pd.isna(gene['HUMAN UNIPROT']) or gene['HUMAN UNIPROT'] == ''):\n",
    "            try:\n",
    "                org, gene_symbol, gene_name, gene_synonyms, gene_ensemble, gene_products = Request_Utilis.Gene_Info_from_EntrezID(human_entrezID)\n",
    "                unique_uniprotids = list(set([item for sublist in [x[2] for x in gene_products] for item in sublist]))\n",
    "                sec_recon_dc.at[i, 'HUMAN UNIPROT'] = unique_uniprotids\n",
    "                print(loop_counter+1, gene_symbol, human_entrezID, unique_uniprotids)\n",
    "            except ValueError:\n",
    "                print(f'No valid Entrez ID for gene {gene_symbol}')\n",
    "            loop_counter += 1\n",
    "\n",
    "            if loop_counter >= update_threshold:\n",
    "                if not sec_recon_dc.equals(sec_recon):\n",
    "                    sec_recon_dc['HUMAN UNIPROT'] = sec_recon_dc['HUMAN UNIPROT'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "                    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                    print(f\"Google Sheet updated on Human Uniprot IDs after {loop_counter} updates\")\n",
    "                else:\n",
    "                    print('HUMAN Uniprot IDs are up-to-date')\n",
    "                loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    sec_recon_dc['HUMAN UNIPROT'] = sec_recon_dc['HUMAN UNIPROT'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on Human Uniprot IDs after {loop_counter} updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- CHO Uniprot IDs -- ##\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "# Collect missing information for CHO identifiers\n",
    "for i, gene in sec_recon_dc.iterrows():\n",
    "    cho_entrezID = str(gene['CHO ENTREZID'])\n",
    "    if cho_entrezID != '':\n",
    "        if (pd.isna(gene['CHO UNIPROT']) or gene['CHO UNIPROT'] == ''):\n",
    "            try:\n",
    "                org, gene_symbol, gene_name, gene_synonyms, gene_ensemble, gene_products = Request_Utilis.Gene_Info_from_EntrezID(cho_entrezID)\n",
    "                unique_uniprotids = list(set([item for sublist in [x[2] for x in gene_products] for item in sublist]))\n",
    "                sec_recon_dc.at[i, 'CHO UNIPROT'] = unique_uniprotids\n",
    "                print(loop_counter+1, gene_symbol, cho_entrezID, unique_uniprotids)\n",
    "            except ValueError:\n",
    "                print(f'No valid Entrez ID for gene {gene_symbol}')\n",
    "            loop_counter += 1\n",
    "\n",
    "            if loop_counter >= update_threshold:\n",
    "                if not sec_recon_dc.equals(sec_recon):\n",
    "                    sec_recon_dc['CHO UNIPROT'] = sec_recon_dc['CHO UNIPROT'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "                    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                    print(f\"Google Sheet updated on CHO Uniprot IDs after {loop_counter} updates\")\n",
    "                else:\n",
    "                    print('CHO Uniprot IDs are up-to-date')\n",
    "                loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    sec_recon_dc['CHO UNIPROT'] = sec_recon_dc['CHO UNIPROT'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on CHO Uniprot IDs after {loop_counter} updates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Mouse Uniprot IDs -- ##\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "# Collect missing information for CHO identifiers\n",
    "for i, gene in sec_recon_dc.iterrows():\n",
    "    mouse_entrezID = str(gene['MOUSE ENTREZID'])\n",
    "    if mouse_entrezID != '':\n",
    "        if (pd.isna(gene['MOUSE UNIPROT']) or gene['MOUSE UNIPROT'] == ''):\n",
    "            try:\n",
    "                org, gene_symbol, gene_name, gene_synonyms, gene_ensemble, gene_products = Request_Utilis.Gene_Info_from_EntrezID(mouse_entrezID)\n",
    "                unique_uniprotids = list(set([item for sublist in [x[2] for x in gene_products] for item in sublist]))\n",
    "                sec_recon_dc.at[i, 'MOUSE UNIPROT'] = unique_uniprotids\n",
    "                print(loop_counter+1, gene_symbol, mouse_entrezID, unique_uniprotids)\n",
    "            except ValueError:\n",
    "                print(f'No valid Entrez ID for gene {gene_symbol}')\n",
    "            loop_counter += 1\n",
    "\n",
    "            if loop_counter >= update_threshold:\n",
    "                if not sec_recon_dc.equals(sec_recon):\n",
    "                    sec_recon_dc['MOUSE UNIPROT'] = sec_recon_dc['MOUSE UNIPROT'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "                    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                    print(f\"Google Sheet updated on Mouse Uniprot IDs after {loop_counter} updates\")\n",
    "                else:\n",
    "                    print('Mouse Uniprot IDs are up-to-date')\n",
    "                loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    sec_recon_dc['MOUSE UNIPROT'] = sec_recon_dc['MOUSE UNIPROT'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on Mouse Uniprot IDs after {loop_counter} updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Subcellular Localization\n",
    "The subcellular localization is divided into two parts. First, we map the subcellular localization to all the genes from the data provided in the paper \"[Global organelle profiling reveals subcellular localization and remodeling at proteome scale](https://www.biorxiv.org/content/10.1101/2023.12.18.572249v1)\". Then, we use the **get_subcellular_localization** from the Request Utilis module to retrieve the subcellular localization of each gene using as input the Uniprot IDs retrieved previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate \"subcell_dict\" for direct mapping into our dataset\n",
    "subcell = pd.read_csv(\"Input/subcellular_localization.csv\")\n",
    "subcell_dict = dict(zip(subcell['Gene_name_canonical'], subcell['consensus graph-based annotation (this study)']))\n",
    "\n",
    "# Standarization of the subcellular compartments to be merged with the compartments in the Sec Recon dataset\n",
    "for key in subcell_dict:\n",
    "    if subcell_dict[key] == 'early_endosome':\n",
    "        subcell_dict[key] = 'Early Endosome'\n",
    "    elif subcell_dict[key] == 'centrosome':\n",
    "        subcell_dict[key] = 'Centrosome'\n",
    "    elif subcell_dict[key] == 'ER':\n",
    "        subcell_dict[key] = 'Endoplasmic Reticulum'\n",
    "    elif subcell_dict[key] == 'mitochondrion':\n",
    "        subcell_dict[key] = 'Mitochondria'\n",
    "    elif subcell_dict[key] == 'stress_granule':\n",
    "        subcell_dict[key] = 'Stress Granule'\n",
    "    elif subcell_dict[key] == 'unclassified':\n",
    "        subcell_dict[key] = None\n",
    "    elif subcell_dict[key] == 'peroxisome':\n",
    "        subcell_dict[key] = 'Peroxisome'\n",
    "    elif subcell_dict[key] == '14-3-3_scaffold':\n",
    "        subcell_dict[key] = None\n",
    "    elif subcell_dict[key] == 'recycling_endosome':\n",
    "        subcell_dict[key] = 'Recycling Endosome'\n",
    "    elif subcell_dict[key] == 'plasma_membrane':\n",
    "        subcell_dict[key] = 'Plasma Membrane'\n",
    "    elif subcell_dict[key] == 'lysosome':\n",
    "        subcell_dict[key] = 'Lysosome'\n",
    "    elif subcell_dict[key] == 'translation':\n",
    "        subcell_dict[key] = 'Translation'\n",
    "    elif subcell_dict[key] == 'actin_cytoskeleton':\n",
    "        subcell_dict[key] = 'Actin Cytoskeleton'\n",
    "    elif subcell_dict[key] == 'cytosol':\n",
    "        subcell_dict[key] = 'Cytosol'\n",
    "    elif subcell_dict[key] == 'nucleus':\n",
    "        subcell_dict[key] = 'Nucleus'\n",
    "    elif subcell_dict[key] == 'ERGIC':\n",
    "        subcell_dict[key] = 'ERGIC'\n",
    "    elif subcell_dict[key] == 'p-body':\n",
    "        subcell_dict[key] = 'P-Body'\n",
    "    elif subcell_dict[key] == 'trans-Golgi':\n",
    "        subcell_dict[key] = 'trans-Golgi'\n",
    "    elif subcell_dict[key] == 'nucleolus':\n",
    "        subcell_dict[key] = 'Nucleolus'\n",
    "    elif subcell_dict[key] == 'proteasome':\n",
    "        subcell_dict[key] = 'Proteasome'\n",
    "    elif subcell_dict[key] == 'Golgi':\n",
    "        subcell_dict[key] = 'Golgi'\n",
    "\n",
    "# Map subcellular localization to the dataset\n",
    "sec_recon_dc['Subcellular Localization'] = sec_recon_dc.apply(lambda row: row['Subcellular Localization'] \n",
    "                                                              if pd.notna(row['Subcellular Localization']) \n",
    "                                                              else subcell_dict.get(row['GENE SYMBOL'], np.nan), axis=1)\n",
    "\n",
    "\n",
    "# Update the Google Sheet file\n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print('Google Sheet updated on Subcellular Localization from \"subcellular_localization.csv\" dataset')\n",
    "else:\n",
    "    print('Subcellular Localizations from \"subcellular_localization.csv\" dataset are up-to-date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Retrieval of Subcellular localizations from Uniprot\n",
    "\n",
    "loop_counter = 0\n",
    "update_threshold = 50\n",
    "\n",
    "for i, row in sec_recon_dc.iterrows():\n",
    "    gene = row['GENE SYMBOL']\n",
    "    # Subcellular compartments are extracted using the Human Uniprot ID\n",
    "    uniprot_ids = row['HUMAN UNIPROT'].split(\", \")\n",
    "    if (pd.isna(row['Subcellular Localization']) or row['Subcellular Localization'] == ''):\n",
    "         if uniprot_ids != ['']:\n",
    "            for uni_id in uniprot_ids:\n",
    "                sub_loc = Request_Utilis.get_subcellular_localization(uni_id)\n",
    "                if sub_loc is not None:\n",
    "                    new_sub_loc = []\n",
    "                    for sloc in sub_loc:\n",
    "                        # Standarization of the subcellular compartments to be included in the Sec Recon dataset\n",
    "                        match_found = False\n",
    "                        if sloc.startswith('Recycling endosome'):\n",
    "                            sloc = 'Recycling Endosome'\n",
    "                            match_found = True\n",
    "                        if sloc.startswith('Late endosome'):\n",
    "                            sloc = 'Late Endosome'\n",
    "                            match_found = True\n",
    "                        if sloc.startswith('Endosome membrane'):\n",
    "                            sloc = 'Endosome'\n",
    "                            match_found = True\n",
    "                        if sloc.startswith('Early endosome'):\n",
    "                            sloc = 'Early Endosome'\n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Endoplasmic Reticulum-Golgi'): \n",
    "                            sloc = 'ERGIC'    \n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Endoplasmic reticulum'):\n",
    "                            sloc = 'Endoplasmic Reticulum'\n",
    "                            match_found = True\n",
    "                        elif 'COPII' in sloc:\n",
    "                            sloc = 'ERGIC'    \n",
    "                            match_found = True\n",
    "                        elif 'cytoskeleton' in sloc:\n",
    "                            sloc = 'Actin Cytoskeleton'\n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Cytoplasm'):\n",
    "                            sloc = 'Cytoplasm'\n",
    "                            match_found = True\n",
    "                        elif 'trans-Golgi' in sloc:\n",
    "                            sloc = 'trans-Golgi'\n",
    "                            match_found = True\n",
    "                        elif 'cis-Golgi' in sloc:\n",
    "                            sloc = 'cis-Golgi'\n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Golgi apparatus'):\n",
    "                            sloc = 'Golgi'\n",
    "                            match_found = True\n",
    "                        elif 'nucleolus' in sloc:\n",
    "                            sloc = 'Nucleolus'\n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Nucleus'):\n",
    "                            sloc = 'Nucleus'\n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Mitochondrion'):\n",
    "                            sloc = 'Mitochondria'\n",
    "                            match_found = True\n",
    "                        elif sloc == 'Membrane' or sloc == 'Cell membrane':\n",
    "                            sloc = 'Plasma Membrane'\n",
    "                            match_found = True\n",
    "                        elif sloc.startswith('Lysosome'):\n",
    "                            sloc = 'Lysosome'\n",
    "                            match_found = True\n",
    "                        elif sloc == 'Secreted':\n",
    "                            match_found = True\n",
    "                        if not match_found:\n",
    "                            continue\n",
    "                            \n",
    "                        new_sub_loc.append(sloc)\n",
    "                            \n",
    "                    break\n",
    "            print(f'Subcellular localization of {gene} is {list(set(new_sub_loc))}')\n",
    "            sec_recon_dc.at[i, 'Subcellular Localization'] = list(set(new_sub_loc))\n",
    "            loop_counter += 1\n",
    "            \n",
    "            # After 50 iterations of the loop, update the Google Sheet file\n",
    "            if loop_counter >= update_threshold:\n",
    "                if not sec_recon_dc.equals(sec_recon):\n",
    "                    sec_recon_dc['Subcellular Localization'] = sec_recon_dc['Subcellular Localization'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "                    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "                    print(f\"Google Sheet updated on Subcellular Localizations from Uniprot after {loop_counter} updates\")\n",
    "                else:\n",
    "                    print('Subcellular Localizations from Uniprot are up-to-date')\n",
    "                loop_counter = 0\n",
    "\n",
    "# Check if there are any remaining updates after exiting the loop\n",
    "if loop_counter > 0 and not sec_recon_dc.equals(sec_recon):\n",
    "    sec_recon_dc['Subcellular Localization'] = sec_recon_dc['Subcellular Localization'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(f\"Google Sheet updated on Subcellular Localizations from Uniprot after {loop_counter} updates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complex Information\n",
    "Here we map Complex Information from the **CORUM** database (https://mips.helmholtz-muenchen.de/corum/#download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load complexes df from the CORUM database\n",
    "complexes = pd.read_excel(\"Input/CORUM download 2022_09_12.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the gene Entrez IDs as keys and all the complexes associated to each ID as values\n",
    "subunit_complex_dict = {}\n",
    "\n",
    "for _, row in complexes.iterrows():\n",
    "    subunit_ids = str(row['subunits(Entrez IDs)']).split(';')\n",
    "    complex_name = row['ComplexName']\n",
    "    for subunit_id in subunit_ids:\n",
    "        if subunit_id.strip():  # Check if the subunit ID is not empty\n",
    "            if subunit_id not in subunit_complex_dict:\n",
    "                # Initialize with a list containing the current complex name\n",
    "                subunit_complex_dict[subunit_id] = [complex_name]\n",
    "            else:\n",
    "                # If the complex name is not already in the list for this ID, append it\n",
    "                if complex_name not in subunit_complex_dict[subunit_id]:\n",
    "                    subunit_complex_dict[subunit_id].append(complex_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add the complex information to each Entrez ID in the SeRecon dataset\n",
    "\n",
    "# Initialize an empty set to store unique complex information\n",
    "unique_complexes = set()\n",
    "\n",
    "for i,row in sec_recon_dc.iterrows():\n",
    "    # Add complex information for Human\n",
    "    human_entrez = row['HUMAN ENTREZID']\n",
    "    hcmpls = subunit_complex_dict.get(human_entrez, 'nan')\n",
    "    if hcmpls != 'nan':\n",
    "        print(f'Human: {human_entrez}, {hcmpls}')\n",
    "        sec_recon_dc.at[i, 'HUMAN PROTEIN COMPLEX'] = hcmpls\n",
    "        # Add each item in the list to the set\n",
    "        unique_complexes.update(hcmpls)\n",
    "    \n",
    "    # Add complex information for Mouse\n",
    "    mouse_entrez = row['MOUSE ENTREZID']\n",
    "    mcmpls = subunit_complex_dict.get(mouse_entrez, 'nan')\n",
    "    if mcmpls != 'nan':\n",
    "        print(f'Mouse: {mouse_entrez}, {mcmpls}')\n",
    "        sec_recon_dc.at[i, 'MOUSE PROTEIN COMPLEX'] = mcmpls\n",
    "        # Add each item in the list to the set\n",
    "        unique_complexes.update(mcmpls)\n",
    "        \n",
    "    # Add complex information for CHO\n",
    "    cho_entrez = row['CHO ENTREZID']\n",
    "    ccmpls = subunit_complex_dict.get(cho_entrez, 'nan')\n",
    "    if ccmpls != 'nan':\n",
    "        print(f'CHO: {cho_entrez}, {ccmpls}')\n",
    "        sec_recon_dc.at[i, 'CHO PROTEIN COMPLEX'] = ccmpls\n",
    "        # Add each item in the list to the set\n",
    "        unique_complexes.update(ccmpls)\n",
    "        \n",
    "sec_recon_dc['HUMAN PROTEIN COMPLEX'] = sec_recon_dc['HUMAN PROTEIN COMPLEX'].apply(lambda x: '; '.join(x) if isinstance(x, list) else x)\n",
    "sec_recon_dc['MOUSE PROTEIN COMPLEX'] = sec_recon_dc['MOUSE PROTEIN COMPLEX'].apply(lambda x: '; '.join(x) if isinstance(x, list) else x)\n",
    "sec_recon_dc['CHO PROTEIN COMPLEX'] = sec_recon_dc['CHO PROTEIN COMPLEX'].apply(lambda x: '; '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated on Protein Complexes\")\n",
    "else:\n",
    "    print('Protein Complexes are up-to-date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to keep\n",
    "columns_to_keep = [\"ComplexName\",\"subunits(Entrez IDs)\",\"GO ID\", \"GO description\",\"FunCat ID\",\"FunCat description\",\"Complex comment\",\"subunits(Gene name)\"]\n",
    "\n",
    "subset_df = complexes[complexes['ComplexName'].isin(unique_complexes)]\n",
    "subset_df = subset_df[columns_to_keep]\n",
    "subset_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "subset_df.to_csv(\"subset_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Secreted Proteins\n",
    "In this section we use the Supplementary Table 2 from the paper [The Human Secretome](https://www.science.org/doi/10.1126/scisignal.aaz0274) to map all the secreted protein information into our reconstruction in the column **SecP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load secretome df\n",
    "secretome = pd.read_excel(\"Input/human_secretome.xlsx\")\n",
    "# Subset of all the genes that are not considered intracellular or membrane-bound (secreted)\n",
    "secretome = secretome[secretome['Annotated category'] != 'Intracellular or membrane-bound']\n",
    "# Generate list of all secreted genes\n",
    "secretome_list = list(secretome['Gene name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in sec_recon_dc.iterrows():\n",
    "    gene_symbol = row['GENE SYMBOL']\n",
    "    if gene_symbol in secretome_list:\n",
    "        sec_recon_dc.loc[i, 'SecP'] = 1\n",
    "        print(gene_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sec_recon_dc.equals(sec_recon):\n",
    "    gsheet_file.update_google_sheet(sec_recon_sheet, sec_recon_dc)\n",
    "    print(\"Google Sheet updated on Secreted Proteins Information\")\n",
    "else:\n",
    "    print('Secreted Proteins Information is up-to-date')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
